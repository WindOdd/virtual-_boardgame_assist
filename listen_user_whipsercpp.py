"""
æ¡ŒéŠèªéŸ³åŠ©ç† - STT æ ¸å¿ƒç³»çµ±
åŠŸèƒ½ï¼šéŸ³è¨Šè¼¸å…¥ â†’ é™å™ª â†’ VAD â†’ STT (è¨˜æ†¶é«”è™•ç†)

æ³¨æ„ï¼špywhispercpp éœ€è¦æª”æ¡ˆè·¯å¾‘ï¼Œä½¿ç”¨ tempfile ä½œç‚ºæ©‹æ¨‘
"""

import sounddevice as sd
import numpy as np
import io
import time
import wave
import tempfile
from datetime import datetime
from collections import deque
from pathlib import Path
import threading

# æª¢æŸ¥ä¾è³´
try:
    from pywhispercpp.model import Model as WhisperModel
except ImportError:
    print("âŒ è«‹å®‰è£: pip install pywhispercpp")
    print("   ä¸¦ä¸‹è¼‰æ¨¡å‹: wget https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-base-q5_1.bin")
    exit(1)

try:
    import torch
except ImportError:
    print("âŒ è«‹å®‰è£: pip install torch")
    exit(1)

try:
    from scipy.io import wavfile
except ImportError:
    print("âŒ è«‹å®‰è£: pip install scipy")
    exit(1)


# ==================== é…ç½®é¡ ====================
class Config:
    """ç³»çµ±é…ç½®"""
    # éŸ³è¨Šåƒæ•¸
    SAMPLE_RATE = 16000          # æ¡æ¨£ç‡ (Hz)
    CHANNELS = 1                 # å–®è²é“
    DTYPE = 'int16'              # æ•¸æ“šé¡å‹
    
    # éŒ„éŸ³æ§åˆ¶
    MAX_RECORDING_DURATION = 30  # æœ€å¤§éŒ„éŸ³æ™‚é•·ï¼ˆç§’ï¼‰
    SILENCE_DURATION = 1.5       # éœéŸ³åˆ¤å®šæ™‚é•·ï¼ˆç§’ï¼‰
    SILENCE_THRESHOLD = 50       # éœéŸ³èƒ½é‡é–¾å€¼
    
    # VAD åƒæ•¸
    VAD_THRESHOLD = 0.5          # Silero VAD é–¾å€¼ (0-1)
    MIN_SPEECH_DURATION = 0.5    # æœ€çŸ­æœ‰æ•ˆèªéŸ³æ™‚é•·ï¼ˆç§’ï¼‰
    MIN_SPEECH_ENERGY = 100      # æœ€å°èªéŸ³èƒ½é‡ï¼ˆå‚™ç”¨æ–¹æ¡ˆï¼‰
    
    # Whisper è¨­å®š
    WHISPER_MODEL = "ggml-base-q5_1.bin"  # æ¨¡å‹è·¯å¾‘
    WHISPER_LANGUAGE = "zh"               # èªè¨€
    WHISPER_THREADS = 4                   # CPU åŸ·è¡Œç·’æ•¸
    
    # ç³»çµ±è¨­å®š
    DEBUG_MODE = True            # é™¤éŒ¯æ¨¡å¼ï¼ˆæœƒä¿å­˜éŸ³è¨Šæª”æ¡ˆï¼‰
    LOG_DIR = Path("logs")       # æ—¥èªŒç›®éŒ„
    
    @classmethod
    def print_config(cls):
        """åˆ—å°ç•¶å‰é…ç½®"""
        print("\n" + "="*60)
        print("ç³»çµ±é…ç½®")
        print("="*60)
        print(f"æ¡æ¨£ç‡: {cls.SAMPLE_RATE} Hz")
        print(f"è²é“æ•¸: {cls.CHANNELS}")
        print(f"æœ€å¤§éŒ„éŸ³æ™‚é•·: {cls.MAX_RECORDING_DURATION} ç§’")
        print(f"éœéŸ³åˆ¤å®šæ™‚é•·: {cls.SILENCE_DURATION} ç§’")
        print(f"VAD é–¾å€¼: {cls.VAD_THRESHOLD}")
        print(f"Whisper æ¨¡å‹: {cls.WHISPER_MODEL}")
        print(f"é™¤éŒ¯æ¨¡å¼: {'é–‹å•Ÿ' if cls.DEBUG_MODE else 'é—œé–‰'}")
        print("="*60 + "\n")


# ==================== éŸ³è¨Šç·©è¡å€ ====================
class AudioBuffer:
    """å¾ªç’°éŸ³è¨Šç·©è¡å€ï¼ˆè¨˜æ†¶é«”ç®¡ç†ï¼‰"""
    
    def __init__(self, max_duration, sample_rate):
        """
        åˆå§‹åŒ–ç·©è¡å€
        
        Args:
            max_duration: æœ€å¤§ç·©è¡æ™‚é•·ï¼ˆç§’ï¼‰
            sample_rate: æ¡æ¨£ç‡
        """
        self.max_samples = int(max_duration * sample_rate)
        self.buffer = deque(maxlen=self.max_samples)
        self.sample_rate = sample_rate
        self.lock = threading.Lock()
    
    def add(self, data):
        """
        æ·»åŠ éŸ³è¨Šæ•¸æ“šï¼ˆç·šç¨‹å®‰å…¨ï¼‰
        
        Args:
            data: numpy array
        """
        with self.lock:
            self.buffer.extend(data.flatten())
    
    def clear(self):
        """æ¸…ç©ºç·©è¡å€"""
        with self.lock:
            self.buffer.clear()
    
    def get_array(self):
        """
        ç²å–å®Œæ•´éŸ³è¨Šæ•¸æ“š
        
        Returns:
            numpy array (int16)
        """
        with self.lock:
            return np.array(list(self.buffer), dtype='int16')
    
    def get_duration(self):
        """
        ç²å–ç•¶å‰ç·©è¡æ™‚é•·
        
        Returns:
            æ™‚é•·ï¼ˆç§’ï¼‰
        """
        with self.lock:
            return len(self.buffer) / self.sample_rate
    
    def get_last_seconds(self, seconds):
        """
        ç²å–æœ€å¾Œ N ç§’çš„éŸ³è¨Š
        
        Args:
            seconds: ç§’æ•¸
            
        Returns:
            numpy array
        """
        samples = int(seconds * self.sample_rate)
        with self.lock:
            data = list(self.buffer)[-samples:]
            return np.array(data, dtype='int16')


# ==================== VAD è™•ç†å™¨ ====================
class VADProcessor:
    """èªéŸ³æ´»å‹•æª¢æ¸¬å™¨ï¼ˆSilero VAD + èƒ½é‡æª¢æ¸¬å‚™ç”¨ï¼‰"""
    
    def __init__(self, sample_rate=16000, threshold=0.5):
        """
        åˆå§‹åŒ– VAD
        
        Args:
            sample_rate: æ¡æ¨£ç‡
            threshold: Silero VAD é–¾å€¼
        """
        self.sample_rate = sample_rate
        self.threshold = threshold
        self.model = None
        self.utils = None
        self._load_model()
    
    def _load_model(self):
        """è¼‰å…¥ Silero VAD æ¨¡å‹"""
        try:
            print("â³ è¼‰å…¥ Silero VAD æ¨¡å‹...")
            self.model, self.utils = torch.hub.load(
                repo_or_dir='snakers4/silero-vad',
                model='silero_vad',
                force_reload=False,
                onnx=False,
                verbose=False
            )
            self.model.eval()
            print("âœ… Silero VAD å·²è¼‰å…¥")
        except Exception as e:
            print(f"âš ï¸  Silero VAD è¼‰å…¥å¤±æ•—: {e}")
            print("   å°‡ä½¿ç”¨ç°¡å–®èƒ½é‡æª¢æ¸¬ä½œç‚ºå‚™ç”¨æ–¹æ¡ˆ")
            self.model = None
    
    def has_speech(self, audio_array):
        """
        æª¢æ¸¬éŸ³è¨Šä¸­æ˜¯å¦åŒ…å«èªéŸ³
        
        Args:
            audio_array: numpy array (int16)
            
        Returns:
            bool: True è¡¨ç¤ºåŒ…å«èªéŸ³
        """
        if self.model is None:
            return self._energy_based_vad(audio_array)
        
        try:
            return self._silero_vad(audio_array)
        except Exception as e:
            print(f"âš ï¸  VAD æª¢æ¸¬éŒ¯èª¤: {e}ï¼Œä½¿ç”¨å‚™ç”¨æ–¹æ¡ˆ")
            return self._energy_based_vad(audio_array)
    
    def _silero_vad(self, audio_array):
        """ä½¿ç”¨ Silero VAD æª¢æ¸¬"""
        # è½‰æ›ç‚º float32 [-1, 1]
        audio_float = audio_array.astype(np.float32) / 32768.0
        audio_tensor = torch.from_numpy(audio_float)
        
        # ç²å–èªéŸ³æ™‚é–“æˆ³
        get_speech_timestamps = self.utils[0]
        speech_timestamps = get_speech_timestamps(
            audio_tensor,
            self.model,
            sampling_rate=self.sample_rate,
            threshold=self.threshold,
            min_speech_duration_ms=int(Config.MIN_SPEECH_DURATION * 1000),
            return_seconds=False
        )
        
        # è¨ˆç®—ç¸½èªéŸ³æ™‚é•·
        if not speech_timestamps:
            return False
        
        total_speech_samples = sum(
            ts['end'] - ts['start'] 
            for ts in speech_timestamps
        )
        total_speech_duration = total_speech_samples / self.sample_rate
        
        return total_speech_duration >= Config.MIN_SPEECH_DURATION
    
    def _energy_based_vad(self, audio_array):
        """ç°¡å–®èƒ½é‡æª¢æ¸¬ï¼ˆå‚™ç”¨æ–¹æ¡ˆï¼‰"""
        # è¨ˆç®—å¹³å‡èƒ½é‡
        energy = np.mean(np.abs(audio_array))
        
        # åˆ¤æ–·æ˜¯å¦è¶…éé–¾å€¼
        return energy > Config.MIN_SPEECH_ENERGY
    
    def get_speech_segments(self, audio_array):
        """
        ç²å–èªéŸ³ç‰‡æ®µçš„æ™‚é–“æˆ³
        
        Args:
            audio_array: numpy array
            
        Returns:
            list of dict: [{'start': 0.5, 'end': 2.3}, ...]
        """
        if self.model is None:
            return []
        
        try:
            audio_float = audio_array.astype(np.float32) / 32768.0
            audio_tensor = torch.from_numpy(audio_float)
            
            get_speech_timestamps = self.utils[0]
            timestamps = get_speech_timestamps(
                audio_tensor,
                self.model,
                sampling_rate=self.sample_rate,
                threshold=self.threshold,
                return_seconds=True
            )
            
            return timestamps
        except:
            return []


# ==================== Whisper STT ====================
class WhisperSTT:
    """Whisper èªéŸ³è½‰æ–‡å­—ï¼ˆè¨˜æ†¶é«”è™•ç†ï¼Œé›¶ç£ç¢Ÿ I/Oï¼‰"""
    
    def __init__(self, model_path, sample_rate=16000, language="zh", n_threads=4):
        """
        åˆå§‹åŒ– Whisper
        
        Args:
            model_path: æ¨¡å‹æª”æ¡ˆè·¯å¾‘
            sample_rate: æ¡æ¨£ç‡
            language: èªè¨€ä»£ç¢¼
            n_threads: CPU åŸ·è¡Œç·’æ•¸
        """
        self.sample_rate = sample_rate
        self.language = language
        self.model = None
        self._load_model(model_path, n_threads)
    
    def _load_model(self, model_path, n_threads):
        """è¼‰å…¥ Whisper æ¨¡å‹"""
        try:
            print(f"â³ è¼‰å…¥ Whisper æ¨¡å‹: {model_path}")
            
            # æª¢æŸ¥æ¨¡å‹æª”æ¡ˆ
            model_path_obj = Path(model_path)
            if not model_path_obj.exists():
                print(f"âŒ æ¨¡å‹æª”æ¡ˆä¸å­˜åœ¨: {model_path}")
                print("\nè«‹é¸æ“‡ä»¥ä¸‹æ–¹å¼ä¸‹è¼‰æ¨¡å‹ï¼š")
                print("\næ–¹å¼ 1: ä½¿ç”¨ wget (Linux/Mac)")
                print("  wget https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-base-q5_1.bin")
                print("\næ–¹å¼ 2: ä½¿ç”¨ curl")
                print("  curl -L -O https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-base-q5_1.bin")
                print("\næ–¹å¼ 3: é‹è¡Œä¸‹è¼‰è…³æœ¬")
                print("  python download_whisper_model.py")
                print("\næ–¹å¼ 4: æ‰‹å‹•å¾ç€è¦½å™¨ä¸‹è¼‰")
                print("  https://huggingface.co/ggerganov/whisper.cpp/tree/main")
                
                # æä¾›è‡ªå‹•ä¸‹è¼‰é¸é …
                auto_download = input("\næ˜¯å¦è‡ªå‹•ä¸‹è¼‰? (y/n): ").strip().lower()
                if auto_download == 'y':
                    if self._auto_download_model(model_path):
                        print("âœ… æ¨¡å‹ä¸‹è¼‰å®Œæˆï¼Œç¹¼çºŒè¼‰å…¥...")
                    else:
                        print("âŒ è‡ªå‹•ä¸‹è¼‰å¤±æ•—ï¼Œè«‹æ‰‹å‹•ä¸‹è¼‰")
                        return
                else:
                    return
            
            # é¡¯ç¤ºæ¨¡å‹è³‡è¨Š
            size_mb = model_path_obj.stat().st_size / (1024 * 1024)
            print(f"ğŸ“Š æ¨¡å‹å¤§å°: {size_mb:.1f} MB")
            
            # è¼‰å…¥æ¨¡å‹
            self.model = WhisperModel(
                str(model_path_obj),
                n_threads=n_threads
            )
            print("âœ… Whisper å·²è¼‰å…¥")
            
        except Exception as e:
            print(f"âŒ Whisper è¼‰å…¥å¤±æ•—: {e}")
            import traceback
            traceback.print_exc()
            self.model = None
    
    def _auto_download_model(self, model_path):
        """è‡ªå‹•ä¸‹è¼‰æ¨¡å‹"""
        try:
            import urllib.request
            
            url = "https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-base-q5_1.bin"
            print(f"ğŸ“¥ ä¸‹è¼‰ä¸­: {url}")
            print("   é€™å¯èƒ½éœ€è¦å¹¾åˆ†é˜...")
            
            def progress_hook(count, block_size, total_size):
                percent = int(count * block_size * 100 / total_size)
                if count % 10 == 0:  # æ¯ 10 å€‹å€å¡Šé¡¯ç¤ºä¸€æ¬¡
                    print(f"   é€²åº¦: {percent}%", end='\r')
            
            urllib.request.urlretrieve(url, model_path, progress_hook)
            print("\nâœ… ä¸‹è¼‰å®Œæˆ")
            return True
            
        except Exception as e:
            print(f"\nâŒ ä¸‹è¼‰å¤±æ•—: {e}")
            return False
    
    def transcribe(self, audio_array):
        """
        è½‰éŒ„éŸ³è¨Šï¼ˆä½¿ç”¨è‡¨æ™‚è¨˜æ†¶é«”æª”æ¡ˆï¼‰
        
        Args:
            audio_array: numpy array (int16)
            
        Returns:
            str: è½‰éŒ„æ–‡å­—
        """
        if self.model is None:
            print("âŒ Whisper æ¨¡å‹æœªè¼‰å…¥")
            return ""
        
        try:
            # ä½¿ç”¨ tempfile å‰µå»ºè‡¨æ™‚æª”æ¡ˆï¼ˆè¨˜æ†¶é«”æ˜ å°„ï¼Œæœ€å°ç£ç¢Ÿ I/Oï¼‰
            import tempfile
            
            with tempfile.NamedTemporaryFile(suffix='.wav', delete=True) as tmp_file:
                # å¯«å…¥ WAV æ ¼å¼
                with wave.open(tmp_file.name, 'wb') as wav_file:
                    wav_file.setnchannels(1)
                    wav_file.setsampwidth(2)
                    wav_file.setframerate(self.sample_rate)
                    wav_file.writeframes(audio_array.tobytes())
                
                # è½‰éŒ„
                start_time = time.time()
                result = self.model.transcribe(
                    tmp_file.name,
                    language=self.language
                )
                elapsed = time.time() - start_time
                
                # è™•ç†ä¸åŒçš„è¿”å›æ ¼å¼
                text = self._extract_text(result)
                
                print(f"â±ï¸  è½‰éŒ„è€—æ™‚: {elapsed:.2f} ç§’")
                
                return text
            # tempfile è‡ªå‹•åˆªé™¤
            
        except Exception as e:
            print(f"âŒ è½‰éŒ„éŒ¯èª¤: {e}")
            import traceback
            traceback.print_exc()
            return ""
    
    def _extract_text(self, result):
        """
        å¾ä¸åŒæ ¼å¼çš„çµæœä¸­æå–æ–‡å­—
        
        Args:
            result: whisper è¿”å›çš„çµæœï¼ˆå¯èƒ½æ˜¯ dict, list, æˆ– objectï¼‰
            
        Returns:
            str: æå–çš„æ–‡å­—
        """
        try:
            # æƒ…æ³ 1: å­—å…¸æ ¼å¼ {'text': '...'}
            if isinstance(result, dict):
                return result.get('text', '').strip()
            
            # æƒ…æ³ 2: åˆ—è¡¨æ ¼å¼ï¼ˆsegment listï¼‰
            elif isinstance(result, list):
                texts = []
                for segment in result:
                    if isinstance(segment, dict):
                        texts.append(segment.get('text', ''))
                    elif hasattr(segment, 'text'):
                        texts.append(segment.text)
                return ' '.join(texts).strip()
            
            # æƒ…æ³ 3: ç‰©ä»¶æ ¼å¼ï¼ˆæœ‰ text å±¬æ€§ï¼‰
            elif hasattr(result, 'text'):
                return result.text.strip()
            
            # æƒ…æ³ 4: å­—ä¸²æ ¼å¼ï¼ˆç›´æ¥è¿”å›æ–‡å­—ï¼‰
            elif isinstance(result, str):
                return result.strip()
            
            # æœªçŸ¥æ ¼å¼ï¼Œå˜—è©¦è½‰æ›ç‚ºå­—ä¸²
            else:
                print(f"âš ï¸  æœªçŸ¥çš„çµæœæ ¼å¼: {type(result)}")
                print(f"   çµæœå…§å®¹: {result}")
                return str(result).strip()
                
        except Exception as e:
            print(f"âš ï¸  æå–æ–‡å­—æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            print(f"   çµæœé¡å‹: {type(result)}")
            print(f"   çµæœå…§å®¹: {result}")
            return ""


# ==================== éŒ„éŸ³ç®¡ç†å™¨ ====================
class AudioRecorder:
    """éŸ³è¨ŠéŒ„éŸ³ç®¡ç†å™¨"""
    
    def __init__(self, buffer):
        """
        åˆå§‹åŒ–éŒ„éŸ³å™¨
        
        Args:
            buffer: AudioBuffer å¯¦ä¾‹
        """
        self.buffer = buffer
        self.stream = None
        self.is_recording = False
        self.silence_start = None
    
    def _callback(self, indata, frames, time_info, status):
        """éŸ³è¨Šè¼¸å…¥å›èª¿å‡½æ•¸"""
        if status:
            print(f"âš ï¸  éŸ³è¨Šç‹€æ…‹: {status}")
        
        if self.is_recording:
            # æ·»åŠ åˆ°ç·©è¡å€
            self.buffer.add(indata)
            
            # æª¢æ¸¬éœéŸ³ï¼ˆç”¨æ–¼è‡ªå‹•åœæ­¢ï¼‰
            energy = np.mean(np.abs(indata))
            
            if energy < Config.SILENCE_THRESHOLD:
                # éœéŸ³é–‹å§‹
                if self.silence_start is None:
                    self.silence_start = time.time()
                # éœéŸ³æŒçºŒè¶…éé–¾å€¼
                elif time.time() - self.silence_start > Config.SILENCE_DURATION:
                    print("ğŸ”‡ æª¢æ¸¬åˆ°æŒçºŒéœéŸ³")
                    self.stop()
            else:
                # æœ‰è²éŸ³ï¼Œé‡ç½®éœéŸ³è¨ˆæ™‚
                self.silence_start = None
    
    def start(self):
        """é–‹å§‹éŒ„éŸ³"""
        if self.is_recording:
            print("âš ï¸  å·²åœ¨éŒ„éŸ³ä¸­")
            return
        
        print("ğŸ¤ é–‹å§‹éŒ„éŸ³...")
        self.is_recording = True
        self.buffer.clear()
        self.silence_start = None
        
        try:
            self.stream = sd.InputStream(
                callback=self._callback,
                channels=Config.CHANNELS,
                samplerate=Config.SAMPLE_RATE,
                dtype=Config.DTYPE
            )
            self.stream.start()
            
        except Exception as e:
            print(f"âŒ éŒ„éŸ³å•Ÿå‹•å¤±æ•—: {e}")
            self.is_recording = False
    
    def stop(self):
        """åœæ­¢éŒ„éŸ³"""
        if not self.is_recording:
            return
        
        self.is_recording = False
        
        if self.stream:
            self.stream.stop()
            self.stream.close()
            self.stream = None
        
        duration = self.buffer.get_duration()
        print(f"â¹ï¸  éŒ„éŸ³åœæ­¢ï¼ˆæ™‚é•·: {duration:.2f} ç§’ï¼‰")
    
    def is_active(self):
        """æª¢æŸ¥æ˜¯å¦æ­£åœ¨éŒ„éŸ³"""
        return self.is_recording


# ==================== ä¸»ç³»çµ± ====================
class VoiceAssistantSTT:
    """èªéŸ³åŠ©ç† STT ç³»çµ±"""
    
    def __init__(self):
        """åˆå§‹åŒ–ç³»çµ±"""
        print("\n" + "="*60)
        print("æ¡ŒéŠèªéŸ³åŠ©ç† - STT ç³»çµ±")
        print("="*60)
        
        # å»ºç«‹æ—¥èªŒç›®éŒ„
        Config.LOG_DIR.mkdir(exist_ok=True)
        
        # åˆå§‹åŒ–çµ„ä»¶
        self.buffer = AudioBuffer(
            Config.MAX_RECORDING_DURATION,
            Config.SAMPLE_RATE
        )
        self.recorder = AudioRecorder(self.buffer)
        self.vad = VADProcessor(
            Config.SAMPLE_RATE,
            Config.VAD_THRESHOLD
        )
        self.stt = WhisperSTT(
            Config.WHISPER_MODEL,
            Config.SAMPLE_RATE,
            Config.WHISPER_LANGUAGE,
            Config.WHISPER_THREADS
        )
        
        Config.print_config()
    
    def process_audio(self):
        """è™•ç†éŒ„éŸ³çš„éŸ³è¨Š"""
        print("\n" + "-"*60)
        print("âš™ï¸  è™•ç†éŸ³è¨Š...")
        
        # 1. ç²å–éŸ³è¨Šæ•¸æ“š
        audio_array = self.buffer.get_array()
        duration = self.buffer.get_duration()
        
        if len(audio_array) == 0:
            print("âŒ ç„¡éŸ³è¨Šæ•¸æ“š")
            return None
        
        print(f"ğŸ“Š éŸ³è¨Šæ™‚é•·: {duration:.2f} ç§’")
        print(f"ğŸ“Š éŸ³è¨Šå¤§å°: {len(audio_array)} æ¨£æœ¬ ({len(audio_array) * 2 / 1024:.1f} KB)")
        
        # 2. VAD æª¢æ¸¬
        print("ğŸ” VAD æª¢æ¸¬ä¸­...")
        has_speech = self.vad.has_speech(audio_array)
        
        if not has_speech:
            print("âŒ æœªæª¢æ¸¬åˆ°æœ‰æ•ˆèªéŸ³")
            return None
        
        print("âœ… æª¢æ¸¬åˆ°èªéŸ³")
        
        # é¡¯ç¤ºèªéŸ³ç‰‡æ®µ
        segments = self.vad.get_speech_segments(audio_array)
        if segments:
            print(f"ğŸ“ èªéŸ³ç‰‡æ®µæ•¸: {len(segments)}")
            for i, seg in enumerate(segments[:3]):  # æœ€å¤šé¡¯ç¤º 3 å€‹
                print(f"   ç‰‡æ®µ {i+1}: {seg['start']:.2f}s - {seg['end']:.2f}s")
        
        # 3. èªéŸ³è½‰æ–‡å­—
        print("ğŸ—£ï¸  èªéŸ³è½‰æ–‡å­—ä¸­...")
        text = self.stt.transcribe(audio_array)
        
        if not text:
            print("âŒ è½‰éŒ„å¤±æ•—æˆ–ç„¡å…§å®¹")
            return None
        
        print(f"âœ… è¾¨è­˜çµæœ: {text}")
        
        # 4. é™¤éŒ¯æ¨¡å¼ï¼šä¿å­˜éŸ³è¨Š
        if Config.DEBUG_MODE:
            self._save_debug_audio(audio_array, text)
        
        print("-"*60 + "\n")
        return text
    
    def _save_debug_audio(self, audio_array, text):
        """ä¿å­˜é™¤éŒ¯éŸ³è¨Šå’Œæ–‡å­—"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # ä¿å­˜éŸ³è¨Š
        audio_file = Config.LOG_DIR / f"audio_{timestamp}.wav"
        wavfile.write(audio_file, Config.SAMPLE_RATE, audio_array)
        
        # ä¿å­˜æ–‡å­—
        text_file = Config.LOG_DIR / f"text_{timestamp}.txt"
        with open(text_file, 'w', encoding='utf-8') as f:
            f.write(text)
        
        print(f"ğŸ’¾ å·²ä¿å­˜: {audio_file.name} & {text_file.name}")
    
    def run_interactive(self):
        """é‹è¡Œäº’å‹•æ¨¡å¼"""
        print("ğŸ® äº’å‹•æ¨¡å¼å•Ÿå‹•")
        print("-"*60)
        print("æŒ‡ä»¤:")
        print("  Enter      - é–‹å§‹/åœæ­¢éŒ„éŸ³")
        print("  q + Enter  - é€€å‡º")
        print("-"*60)
        
        try:
            while True:
                cmd = input("\nğŸ‘‰ ").strip().lower()
                
                if cmd == 'q':
                    print("ğŸ‘‹ å†è¦‹ï¼")
                    break
                
                # åˆ‡æ›éŒ„éŸ³ç‹€æ…‹
                if not self.recorder.is_active():
                    # é–‹å§‹éŒ„éŸ³
                    self.recorder.start()
                    print("ğŸ’¡ æŒ‰ Enter åœæ­¢éŒ„éŸ³")
                else:
                    # åœæ­¢éŒ„éŸ³ä¸¦è™•ç†
                    self.recorder.stop()
                    self.process_audio()
        
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ ç¨‹å¼ä¸­æ–·")
        
        finally:
            if self.recorder.is_active():
                self.recorder.stop()
    
    def run_button_mode(self):
        """é‹è¡ŒæŒ‰éˆ•æ¨¡å¼ï¼ˆæ¨¡æ“¬ï¼‰"""
        print("ğŸ”˜ æŒ‰éˆ•æ¨¡å¼å•Ÿå‹•")
        print("-"*60)
        print("æŒ‰ Enter æ¨¡æ“¬æŒ‰ä¸‹æŒ‰éˆ•ï¼ˆé–‹å§‹éŒ„éŸ³ï¼‰")
        print("éŒ„éŸ³å°‡åœ¨éœéŸ³æˆ–è¶…æ™‚å¾Œè‡ªå‹•åœæ­¢")
        print("è¼¸å…¥ 'q' é€€å‡º")
        print("-"*60)
        
        try:
            while True:
                cmd = input("\nğŸ‘‰ æŒ‰éˆ•: ").strip().lower()
                
                if cmd == 'q':
                    print("ğŸ‘‹ å†è¦‹ï¼")
                    break
                
                # é–‹å§‹éŒ„éŸ³
                self.recorder.start()
                
                # ç­‰å¾…è‡ªå‹•åœæ­¢æˆ–æ‰‹å‹•åœæ­¢
                start = time.time()
                while self.recorder.is_active():
                    time.sleep(0.1)
                    # æª¢æŸ¥è¶…æ™‚
                    if time.time() - start > Config.MAX_RECORDING_DURATION:
                        print("â±ï¸  é”åˆ°æœ€å¤§éŒ„éŸ³æ™‚é•·")
                        self.recorder.stop()
                        break
                
                # è™•ç†éŸ³è¨Š
                self.process_audio()
        
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ ç¨‹å¼ä¸­æ–·")
        
        finally:
            if self.recorder.is_active():
                self.recorder.stop()


# ==================== ä¸»ç¨‹å¼å…¥å£ ====================
def main():
    """ä¸»ç¨‹å¼"""
    # å‰µå»ºç³»çµ±
    assistant = VoiceAssistantSTT()
    
    # é¸æ“‡æ¨¡å¼
    print("é¸æ“‡é‹è¡Œæ¨¡å¼:")
    print("  1 - äº’å‹•æ¨¡å¼ï¼ˆæ‰‹å‹•æ§åˆ¶éŒ„éŸ³ï¼‰")
    print("  2 - æŒ‰éˆ•æ¨¡å¼ï¼ˆè‡ªå‹•åœæ­¢ï¼‰")
    
    choice = input("\nè«‹é¸æ“‡ (1/2): ").strip()
    
    if choice == '2':
        assistant.run_button_mode()
    else:
        assistant.run_interactive()


if __name__ == "__main__":
    main()