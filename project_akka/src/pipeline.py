"""
Project Akka - Pipeline Module
Orchestrator for Hybrid Routing (Semantic -> LLM)
Refactored for Stateless Architecture (v9.6)
"""

import logging
import asyncio
import random
from pathlib import Path
from typing import Optional, List, Dict, Any
from dataclasses import dataclass

try:
    from .llm import LLMServiceManager
except ImportError:
    from llm.manager import LLMServiceManager

# Project modules
try:
    from .boardgame_utils import ConfigLoader, PromptManager
    from .data_manager import get_data_manager
    from .semantic_router import SemanticRouter
except ImportError:
    from boardgame_utils import ConfigLoader, PromptManager
    from data_manager import get_data_manager
    from semantic_router import SemanticRouter

logger = logging.getLogger(__name__)

@dataclass
class RouterResult:
    intent: str
    confidence: float = 0.0
    source: str = "unknown"

@dataclass
class PipelineResult:
    response: str
    intent: Optional[str] = None
    confidence: float = 0.0
    source: str = "unknown"

class Pipeline:
    def __init__(self, config_dir: Optional[Path] = None):
        self.config_dir = config_dir or Path(__file__).parent.parent / "config"
        self.data_manager = get_data_manager()
        self.system_config = {}
        self.semantic_routes = {}
        
        # 1. Load Configurations
        self._load_configs()
        
        # 2. Initialize Semantic Router
        embedding_config = self.system_config.get("model", {}).get("embedding", {})
        self.semantic_router = SemanticRouter(
            model_config=embedding_config,
            routes_config=self.semantic_routes
        )
        
        # 3. Initialize LLM Manager
        self.llm_manager = LLMServiceManager(self.system_config)
        self.local_llm = self.llm_manager.get_local()
        self.cloud_llm = self.llm_manager.get_cloud()

    def _load_configs(self) -> None:
        """Load all YAML configurations."""
        try:
            self.store_info = ConfigLoader(self.config_dir / "store_info.yaml").load()
            self.intent_map = ConfigLoader(self.config_dir / "intent_map.yaml").load()
            self.local_prompts = PromptManager(self.config_dir / "prompts_local.yaml")
            self.cloud_prompts = PromptManager(self.config_dir / "prompts_cloud.yaml")
            self.system_config = ConfigLoader(self.config_dir / "system_config.yaml").load()
            
            # Optional Configs
            try:
                self.semantic_routes = ConfigLoader(self.config_dir / "semantic_routes.yaml").load()
            except Exception:
                logger.warning("semantic_routes.yaml missing.")
                self.semantic_routes = {}
            
            logger.info("Config loaded.")
        except Exception as e:
            logger.error(f"Config load failed: {e}")
            self.store_info = {}
            self.semantic_routes = {}
            self.intent_map = {}
            self.system_config = {}

    def reload_configs(self) -> None:
        logger.info("Reloading configurations...")
        self._load_configs()
        embedding_config = self.system_config.get("model", {}).get("embedding", {})
        self.semantic_router = SemanticRouter(embedding_config, self.semantic_routes)

    async def process(
        self, 
        user_input: str, 
        history: List[Dict[str, Any]] = None, 
        game_context: Dict[str, Any] = None, # <--- æ–°å¢é€™è£¡
        llm_service=None
    ) -> PipelineResult:
        """
        Main processing pipeline.
        Args:
            user_input: The current user query.
            history: List of past turns (provided by Client) to extract context.
        """
        user_input = user_input.strip()
        if not user_input:
            return PipelineResult(response="...", source="empty")

        # === DEBUG: Pipeline å…¥å£è³‡æ–™ ===
        logger.info("=" * 50)
        logger.info("ğŸ” [DEBUG] Pipeline.process() å…¥å£è³‡æ–™:")
        logger.info(f"   user_input: {user_input}")
        logger.info(f"   history: {history}")
        logger.info(f"   game_context: {game_context}")
        logger.info("=" * 50)

        # ============================================================
        # [NEW] Stage 0: Context Extraction (Stateless Logic)
        # ============================================================
        # Extract recent context with queries (INTENT: query format)
        recent_context = self._extract_recent_context(history, window=3, max_length=80)

        # Legacy format for backward compatibility (intent chain)
        context_str = ""
        if history:
            # === DEBUG: æª¢æŸ¥ history ä¸­çš„æ„åœ–æ¨™ç±¤ ===
            logger.info("ğŸ” [DEBUG] Context Extraction - æª¢æŸ¥ history:")
            for i, msg in enumerate(history):
                role = msg.get("role", "?")
                intent = msg.get("intent", "N/A")
                content = msg.get("content", "")[:30]  # åªé¡¯ç¤ºå‰ 30 å­—
                logger.info(f"   [{i}] role={role}, intent={intent}, content={content}...")

            # [ä¿®æ­£] ç¯©é¸è¦å‰‡ï¼šå¾ assistant çš„å›æ‡‰æå– intentï¼ˆå› ç‚ºåªæœ‰ server å›æ‡‰æ‰æœƒåŠ ä¸Š intentï¼‰
            recent_assistant_logs = [
                msg for msg in history
                if msg.get("role") == "assistant" and msg.get("intent")
            ]

            logger.info(f"ğŸ” [DEBUG] ç¬¦åˆæ¢ä»¶çš„ assistant logs æ•¸é‡: {len(recent_assistant_logs)}")

            if recent_assistant_logs:
                # å–å‡ºæœ€å¾Œ 2 æ¬¡çš„æ„åœ–è»Œè·¡ (ä¾‹å¦‚: RULES -> STORE_PRICING)
                last_intents = [msg["intent"] for msg in recent_assistant_logs[-2:]]
                context_str = " -> ".join(last_intents)
                logger.info(f"ğŸ•µï¸ Context Extracted (legacy): {context_str}")
            else:
                logger.info("âš ï¸ [DEBUG] æ²’æœ‰æ‰¾åˆ°å¸¶ intent çš„ assistant logï¼Œcontext_str ç‚ºç©º")

        # Log new format
        if recent_context:
            logger.info("ğŸ” [DEBUG] Recent Context (new format):")
            for ctx in recent_context:
                logger.info(f"   - {ctx}")

        # [NEW] Get top 3 semantic scores for LLM Router
        top_matches = self.semantic_router.get_top_matches(user_input, top_k=3)
        if top_matches:
            logger.info("ğŸ” [DEBUG] Top 3 Semantic Scores:")
            for intent, score in top_matches:
                logger.info(f"   - {intent}: {score:.4f}")

        # [NEW] Load STT keywords if game_id is provided
        stt_keywords = []
        if game_context and game_context.get("game_id"):
            game_id = game_context.get("game_id")
            stt_keywords = self._load_stt_keywords(game_id)
            if stt_keywords:
                logger.info(f"ğŸ” [DEBUG] STT Keywords loaded for {game_id}: {len(stt_keywords)} keywords")

        # --- Stage 1: Semantic Vector Routing (FastPath) ---
        semantic_intent, score = self.semantic_router.route(user_input)
    
        if semantic_intent:
            logger.info(f"âš¡ FastPath Hit: {semantic_intent} (Score: {score:.4f})")
            response, source, override_intent = await self._dispatch(semantic_intent, user_input, None)
            final_intent = override_intent if override_intent else semantic_intent
            return PipelineResult(
                response=response,
                intent=final_intent,
                confidence=float(score),
                source=f"fastpath_{source}"
            )

        # --- Stage 2: LLM Intent Routing ---
        if self.llm_manager is None:
            return PipelineResult(response="ç³»çµ±ç¶­è­·ä¸­...", source="error")

        logger.info("ğŸ¢ FastPath Miss. Engaging LLM Router...")

        # [MODIFY] å°‡ Context æ³¨å…¥ Prompt
        # Build semantic scores block
        if top_matches:
            scores_lines = "\n".join([f"- {intent}: {score:.2f}" for intent, score in top_matches])
            scores_block = f"[Semantic Scores]\n{scores_lines}\n\n"
        else:
            scores_block = ""

        # Build context string from recent_context (new format)
        if recent_context:
            context_lines = "\n".join([f"- {ctx}" for ctx in recent_context])
            context_block = f"[Recent Context]\n{context_lines}\n\n"
        else:
            context_block = ""

        # Build STT keywords block
        if stt_keywords:
            keywords_str = ", ".join(stt_keywords[:20])  # Limit to first 20 keywords
            keywords_block = f"[Game Keywords]\n{keywords_str}\n\n"
        else:
            keywords_block = ""

        # Legacy context format (for backward compatibility)
        if context_str and not recent_context:
            legacy_context = f"[Context: {context_str}]\n\n"
        else:
            legacy_context = ""

        # Construct final input
        final_input = f"{scores_block}{context_block}{keywords_block}{legacy_context}[User Input] {user_input}"

        # å‚³é€ final_input çµ¦ Router
        router_result = await self._route_with_llm(final_input, self.local_llm)
        # ä½¿ç”¨ Logger è€Œä¸æ˜¯ Printï¼Œä¿æŒ Log ä¹¾æ·¨
        logger.info(f"Router Result: {router_result}") 

        # --- Stage 3: Safety Filter ---
        if router_result.intent == "SENSITIVE":
            if self._check_allowlist(user_input):
                router_result.intent = "RULES"
        context_pack = {
            "history": history,
            "game_context": game_context
        }
        # === DEBUG: å‚³å…¥ Dispatch çš„ context_pack ===
        logger.info("ğŸ” [DEBUG] context_pack å‚³å…¥ _dispatch:")
        logger.info(f"   game_context: {context_pack.get('game_context')}")
        logger.info(f"   history items: {len(context_pack.get('history') or [])}")
        # --- Stage 4: Dispatch ---
        response, source, override_intent = await self._dispatch(
            router_result.intent, 
            user_input, 
            context_pack
        )
        
        # å¦‚æœæœ‰ override_intentï¼ˆå¦‚ ERRORï¼‰ï¼Œä½¿ç”¨å®ƒï¼›å¦å‰‡ç”¨åŸæœ¬çš„ intent
        final_intent = override_intent if override_intent else router_result.intent
        
        return PipelineResult(
            response=response,
            intent=final_intent,
            confidence=router_result.confidence,
            source=source
        )

    async def _route_with_llm(self, final_input: str, llm_service) -> RouterResult:
        """
        Sends the constructed input (with context) to the Local LLM.
        """
        router_config = self.local_prompts.get_task_config("router")
        system_prompt = router_config.get("system_prompt", "")
        
        if not system_prompt:
            logger.warning("Router system prompt is empty!")
            
        if not self.local_llm:
            return RouterResult(intent="UNKNOWN", confidence=0.0, source="error")
            
        try:
            # === DEBUG: Router LLM Prompt ===
            logger.info("=" * 50)
            logger.info("ğŸ§  [DEBUG] Router LLM Prompt:")
            logger.info(f"   [System Prompt] (length: {len(system_prompt)} chars):")
            logger.info(f"   {system_prompt[:500]}..." if len(system_prompt) > 500 else f"   {system_prompt}")
            logger.info(f"   [User Input]: {final_input}")
            logger.info("=" * 50)
            
            # ç›´æ¥ä½¿ç”¨å·²ç¶“çµ„å¥½çš„ final_input
            response = await self.local_llm.generate_json(final_input, system_prompt)
            intent = response.get("intent", "UNKNOWN")
            confidence = response.get("confidence", 0.0)
            return RouterResult(intent=intent, confidence=confidence, source="llm")
        except Exception as e:
            logger.error(f"Router LLM Error: {e}")
            return RouterResult(intent="UNKNOWN", confidence=0.0, source="fallback")

    def _load_stt_keywords(self, game_id: str) -> List[str]:
        """
        Load STT keywords for a specific game.

        Args:
            game_id: Game identifier (e.g., "Carcassonne", "Splendor")

        Returns:
            List of STT keywords for the game
        """
        try:
            # Construct file path
            keywords_file = Path(__file__).parent.parent / "data" / "stt_keywords" / f"{game_id}.txt"

            if not keywords_file.exists():
                logger.warning(f"STT keywords file not found: {keywords_file}")
                return []

            # Read keywords (one per line)
            with open(keywords_file, 'r', encoding='utf-8') as f:
                keywords = [line.strip() for line in f if line.strip()]

            logger.info(f"âœ… Loaded {len(keywords)} STT keywords for {game_id}")
            return keywords

        except Exception as e:
            logger.error(f"Failed to load STT keywords for {game_id}: {e}")
            return []

    def _extract_recent_context(
        self,
        history: Optional[List[Dict[str, Any]]],
        window: int = 3,
        max_length: int = 80
    ) -> List[str]:
        """
        Extract recent conversation context in format: "INTENT: user_query"

        Args:
            history: Full conversation history
            window: Number of recent turns to extract (default: 3)
            max_length: Maximum length per query (default: 80 chars)

        Returns:
            List of formatted context strings, e.g.:
            ["STORE_SALES: ä½ å€‘æœ‰è³£å¡å¦å³¶å—", "RULES: è¦æ€éº¼è²·ç™¼å±•å¡"]
        """
        if not history:
            return []

        context = []

        # Iterate through history to find assistant messages with intent
        for i, msg in enumerate(history):
            if msg.get("role") == "assistant" and msg.get("intent"):
                # Find the corresponding user query (previous message)
                if i > 0 and history[i-1].get("role") == "user":
                    user_query = history[i-1].get("content", "").strip()
                    intent = msg.get("intent")

                    # Truncate long queries
                    if len(user_query) > max_length:
                        user_query_short = user_query[:max_length] + "..."
                    else:
                        user_query_short = user_query

                    # Format: "INTENT: query"
                    context.append(f"{intent}: {user_query_short}")

        # Return most recent N entries
        return context[-window:]

    def _check_allowlist(self, user_input: str) -> bool:
        try:
            games = self.data_manager.list_games()
            for game in games:
                allowlist = game.metadata.get("allowlist_keywords", [])
                for keyword in allowlist:
                    if keyword in user_input: return True
        except Exception:
            pass
        return False

    async def _dispatch(self, intent: str, user_input: str, context: Any = None) -> tuple[str, str, str]:
        """
        Returns: (response, source, override_intent)
        override_intent: None è¡¨ç¤ºä½¿ç”¨åŸæœ¬çš„ intent, "ERROR" è¡¨ç¤ºéŒ¯èª¤
        """
        responses_map = self.store_info.get("responses", {})
        
        # 1. Static Responses
        if intent in responses_map:
            candidates = responses_map[intent]
            if candidates: 
                return (random.choice(candidates), "content_static", None)
        
        # 2. Logic Handlers
        logic_intents = self.intent_map.get("logic_intents", {})
        if intent in logic_intents:
            logic_config = logic_intents[intent]
            handler = logic_config.get("handler", "")
            
            if handler == "local_llm" and self.local_llm:
                # é€™è£¡èª¿ç”¨ Persona é€²è¡Œé–’èŠ
                task = logic_config.get("task", "casual_chat")
                sys_prompt = self.local_prompts.get_task_config("casual_chat").get("system_prompt", "")
                resp = await self.local_llm.generate(user_input, sys_prompt)
                return (resp.content, "local_llm_gen", None)
            elif handler in ["online_llm", "cloud_llm", "cloud_rag"]:
                if self.cloud_llm:
                    return await self._handle_rules_query(user_input, context)
                else:
                    return ("æŠ±æ­‰ï¼Œé›²ç«¯å¤§è…¦é€£ç·šæœ‰é»å•é¡Œï¼Œè«‹ç¨å¾Œå†è©¦ã€‚", "error", "ERROR")
            elif handler == "reject":
                return (logic_config.get("response", "æŠ±æ­‰"), "reject", None)

        # 3. Fallback
        fallback = self.store_info.get("responses", {}).get("UNKNOWN_FALLBACK", ["æŠ±æ­‰ï¼Ÿ"])
        return (random.choice(fallback), "fallback", None)
    # src/pipeline.py -> class Pipeline

    # [æ–°å¢] æ•´å€‹å‡½å¼
    async def _handle_rules_query(self, user_input: str, context: Dict[str, Any]) -> tuple[str, str]:
        """
        å°ˆé–€è™•ç† RULES æ„åœ–çš„é‚è¼¯å‡½å¼
        ä¿®æ­£é‡é»ï¼šå°‡ history æ ¼å¼åŒ–ä¸¦æ³¨å…¥ System Prompt
        """
        # 1. å–å¾—éŠæˆ²åç¨± & æ­·å²ç´€éŒ„
        ctx = context if isinstance(context, dict) else {}
        game_ctx = ctx.get("game_context", {}) or {}
        game_id = game_ctx.get("game_id", "carcassonne") 
        history = ctx.get("history", []) # å–å¾—æ­·å²ç´€éŒ„ List
        
        # === DEBUG: _handle_rules_query å…¥å£è³‡æ–™ ===
        logger.info("=" * 50)
        logger.info("ğŸ” [DEBUG] _handle_rules_query() è³‡æ–™æª¢æŸ¥:")
        logger.info(f"   raw context: {ctx}")
        logger.info(f"   game_ctx: {game_ctx}")
        logger.info(f"   game_id (ä½¿ç”¨ä¸­): {game_id}")
        logger.info(f"   history length: {len(history) if history else 0}")
        logger.info("=" * 50)
        
        # 2. é€é DataManager å–å¾—è¦å‰‡å…§å®¹
        rule_content = self.data_manager.get_rules(game_id)
        if not rule_content:
            logger.warning(f"Rulebook not found for game_id: {game_id}")
            rule_content = "ï¼ˆç³»çµ±æç¤ºï¼šç›®å‰æ‰¾ä¸åˆ°æ­¤éŠæˆ²çš„è©³ç´°è¦å‰‡è³‡æ–™ï¼Œè«‹ä¾æ“šæ‚¨çš„é€šç”¨çŸ¥è­˜å›ç­”ã€‚ï¼‰"
        else:
            logger.info(f"âœ… [DEBUG] Rulebook loaded for {game_id}, length: {len(rule_content)} chars")

        # 3. è®€å– System Prompt Template
        # å‡è¨­ prompts_cloud.yaml è£¡æœ‰ {INJECTED_RAG_CONTENT} å’Œ {history} å…©å€‹ä½”ä½ç¬¦
        task_config = self.cloud_prompts.get_task_config("rules_explainer")
        system_template = task_config.get("system_prompt", "")
        
        # 4. [å„ªåŒ–] æ ¼å¼åŒ– History - åªä¿ç•™ RULES ç›¸é—œçš„å°è©±
        history_str = ""
        if history:
            # éæ¿¾ï¼šåªä¿ç•™ intent ç‚º RULES æˆ– None çš„è¨Šæ¯
            # None çš„æƒ…æ³æ˜¯ user è¨Šæ¯ï¼ˆæ²’æœ‰ intentï¼‰ï¼Œä½†å¦‚æœå‰å¾Œæœ‰ RULES å‰‡ä¿ç•™
            filtered_history = []
            
            for i, msg in enumerate(history):
                intent = msg.get("intent")
                role = msg.get("role")
                
                # ä¿ç•™æ¢ä»¶ï¼š
                # 1. assistant ä¸” intent æ˜¯ RULES
                # 2. user è¨Šæ¯ï¼ˆéœ€è¦çœ‹ä¸‹ä¸€å€‹ assistant çš„ intent æ˜¯å¦ç‚º RULESï¼‰
                if role == "assistant" and intent == "RULES":
                    # æŠŠå‰ä¸€å‰‡ user è¨Šæ¯ä¹ŸåŠ å…¥ï¼ˆå¦‚æœé‚„æ²’åŠ å…¥ï¼‰
                    if i > 0 and history[i-1].get("role") == "user":
                        prev_msg = history[i-1]
                        if prev_msg not in filtered_history:
                            filtered_history.append(prev_msg)
                    filtered_history.append(msg)
            
            # æ ¼å¼åŒ–
            if filtered_history:
                history_lines = []
                for msg in filtered_history:
                    role = msg.get("role", "unknown")
                    content = msg.get("content", "")
                    history_lines.append(f"{role}: {content}")
                history_str = "\n".join(history_lines)
                logger.info(f"âœ… [DEBUG] History filtered (RULES only): {len(filtered_history)} msgs from {len(history)} total")
            else:
                history_str = "(No RULES-related conversation)"
                logger.info("âš ï¸ [DEBUG] No RULES history found, using empty context")
        else:
            history_str = "(No previous conversation)"
            logger.info("âš ï¸ [DEBUG] No history provided")

        # 5. æ³¨å…¥è®Šæ•¸ (è¦å‰‡ + æ­·å²)
        # æ³¨æ„ï¼šé€™è£¡ä½¿ç”¨ replace ç°¡å–®æ›¿æ›ã€‚å»ºè­°ç¢ºèª YAML è£¡çš„ä½”ä½ç¬¦åç¨±æ˜¯å¦ä¸€è‡´ã€‚
        final_system_prompt = (
            system_template
            .replace("{INJECTED_RAG_CONTENT}", rule_content)
            .replace("{history}", history_str) 
        )
        
        # 6. å‘¼å«é›²ç«¯å¤§è…¦
        try:
            # === DEBUG: Cloud LLM Prompt ===
            logger.info("=" * 50)
            logger.info("â˜ï¸ [DEBUG] Cloud LLM Prompt:")
            logger.info(f"   [System Prompt] (length: {len(final_system_prompt)} chars)")
            logger.info(f"   --- System Prompt å‰ 800 å­— ---")
            logger.info(final_system_prompt[:800] if len(final_system_prompt) > 800 else final_system_prompt)
            logger.info(f"   --- System Prompt å¾Œ 500 å­— ---")
            logger.info(final_system_prompt[-500:] if len(final_system_prompt) > 500 else "(åŒä¸Š)")
            logger.info(f"   [User Input]: {user_input}")
            logger.info("=" * 50)
            
            # å‘¼å« Cloud LLM
            # user_input æ˜¯ç•¶å‰ä½¿ç”¨è€…çš„å•é¡Œ
            raw_response = await self.cloud_llm.generate(
                user_input,
                system_prompt=final_system_prompt
            )
            
            response_text = raw_response.content if hasattr(raw_response, "content") else str(raw_response)
            return (response_text, "cloud_gen", None)  # None = ä½¿ç”¨åŸæœ¬ intent
            
        except Exception as e:
            logger.error(f"Cloud Handling Error: {e}")
            return ("æŠ±æ­‰ï¼Œé›²ç«¯å¤§è…¦é€£ç·šæœ‰é»å•é¡Œï¼Œè«‹ç¨å¾Œå†è©¦ã€‚", "error", "ERROR")  # ERROR intent

def create_pipeline(config_dir: Optional[Path] = None) -> Pipeline:
    return Pipeline(config_dir=config_dir)

if __name__ == "__main__":
    # Test Standalone Pipeline
    import time 
    logging.basicConfig(level=logging.INFO)
    p = create_pipeline()
    print("Pipeline Initialized.")
    print("=============================")
    
    # æ¸¬è©¦ 1: ä¸€èˆ¬ FastPath
    print("\n--- Test 1: FastPath (No History) ---")
    print(asyncio.run(p.process("æƒ³å°¿å°¿")))
    
    # æ¸¬è©¦ 2: ä¸€èˆ¬ LLM Router
    print("\n--- Test 2: LLM Router (No History) ---")
    print(asyncio.run(p.process("ä½ å¥½æˆ‘æƒ³çŸ¥é“ä½ å€‘æœ‰è³£å“ªäº›æ¡ŒéŠ")))
    
    # æ¸¬è©¦ 3: Context Aware (æ¨¡æ“¬ Client å¸¶å…¥ History)
    print("\n--- Test 3: Context Injection (Simulate Client History) ---")
    # æƒ…å¢ƒï¼šä¸Šä¸€è¼ªå•äº†åƒ¹æ ¼ï¼Œé€™ä¸€è¼ªåªå•ã€Œé‚£å‡æ—¥å‘¢ï¼Ÿã€
    mock_history = [
        {"role": "user", "content": "å¹³æ—¥å¤šå°‘éŒ¢ï¼Ÿ", "intent": "STORE_PRICING"},
        {"role": "assistant", "content": "å¹³æ—¥ 60 å…ƒ..."}
    ]
    # æˆ‘å€‘æœŸæœ›é€™å¥æ¨¡ç³Šçš„ã€Œé‚£å‡æ—¥å‘¢ã€èƒ½å› ç‚º History è€Œè¢«è­˜åˆ¥æ­£ç¢º
    print(f"Input: é‚£å‡æ—¥å‘¢ï¼Ÿ (with context: STORE_PRICING)")
    print(asyncio.run(p.process("é‚£å‡æ—¥å‘¢ï¼Ÿ", history=mock_history)))
    
    print("\n=============================")
    print("Tests Completed.")